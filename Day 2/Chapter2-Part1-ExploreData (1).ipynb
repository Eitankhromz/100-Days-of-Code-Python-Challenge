{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=dimgray>Chapter 2 ~ Housing Prices\n",
    "_This notebook contains some sample code from Chapter 2._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=dimgray>Part 1 ~ Explore Data</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=blue>Import needed Modules</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##!pip install scikit-learn-intelex  #install patches to speed up processing (only need to run this ONCE on your computer or Colab session)\n",
    "#from sklearnex import patch_sklearn #import the patches\n",
    "#patch_sklearn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#general libraries needed\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "#special graphing modules used\n",
    "from pandas.plotting import scatter_matrix\n",
    "\n",
    "#scikit learn imports\n",
    "import sklearn.linear_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OrdinalEncoder, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "#not necessary but helps to visualize pipelines and models\n",
    "from sklearn import set_config\n",
    "set_config(display='diagram')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=blue>Function Definitions</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to verify the existence of a file in the current working directory and download it if not\n",
    "import os,urllib, urllib.request, sys, tarfile\n",
    "def downloadDataResource(file,sourcePath,compressed=None):\n",
    "    if not os.path.isfile(file):\n",
    "        try:\n",
    "            urllib.request.urlretrieve(sourcePath+(compressed if compressed else file),(compressed if compressed else file))\n",
    "            print(\"Downloaded\", (compressed if compressed else file) )\n",
    "            if compressed:\n",
    "                ucomp = tarfile.open(compressed)\n",
    "                ucomp.extractall()\n",
    "                ucomp.close()\n",
    "                print(\"File uncompressed.\")\n",
    "        except:\n",
    "            print(\"ERROR: File\", (compressed if compressed else file), \"not found. Data source missing.\")\n",
    "    else:\n",
    "        print(\"Data resource\", file, \"already downloaded.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=blue>Source Data</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'https://raw.githubusercontent.com/ageron/handson-ml2/master/datasets/housing/'\n",
    "compressedfile = \"housing.tgz\"\n",
    "filename = 'housing.csv'\n",
    "\n",
    "#download data files if not currently downloaded into the current working directory\n",
    "downloadDataResource(filename, path, compressedfile)\n",
    "\n",
    "#create the dataframe\n",
    "housing = pd.read_csv(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  <font color=blue>Analyze the Dataset</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#each row of the data represents a district\n",
    "housing.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#review attribute data types\n",
    "#Note that all attributes are numeric except for the last one that is text/string\n",
    "housing.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#perform statistical analysis on numeric attributes\n",
    "housing.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=blue>Look for Correlations in the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing.corr( numeric_only = True ) #addition of numeric_only helps to remove warning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore what is Correlated with Predicted Value (Median House Value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from the graph above, can see the correlation of housing price and location (latitude/longitude)\n",
    "#let's look at it statistically by analyzing the correlation of median_house_value to all other attributes\n",
    "corr_matrix = housing.corr( numeric_only = True )\n",
    "corr_matrix[\"median_house_value\"].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#there is a linear relationship as home values increase as incomes increase (no surprise)\n",
    "\n",
    "#another great way to look for more than just linear relationships is to create a scatter matrix plot\n",
    "scatter_matrix(housing[['median_house_value', 'median_income', 'total_rooms', 'housing_median_age']], figsize=(12,8))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this of course continues to show the linear relationship between median income and median house value\n",
    "#explore this relationship more specifically ...\n",
    "housing.plot(kind=\"scatter\", x=\"median_income\", y=\"median_house_value\",alpha=.1)\n",
    "plt.show()\n",
    "\n",
    "#note the price cap at 500,000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=red>Because Median Income is so highly correlated with our predicted variable, we will want to see that our model is stratified to ensure a well-balanced training and test data set. See below!</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=blue>Explore Data Distribution</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#graph using matplotlib.pyplot all numeric attributes of housing\n",
    "#a histogram shows data distribution \n",
    "housing.hist(bins=50, figsize=(20,15))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate attribute <i>Medium Income</i> and consider ways to normalize distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing[\"median_income\"].hist()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a new attribute that bins (pandas qcut function) Median Income into 5 different bins with equal distribution\n",
    "housing[\"income_cat\"] = pd.qcut(housing[\"median_income\"], q=5, labels=[1, 2, 3, 4, 5])\n",
    "\n",
    "#see that this column has a equal distribution of income data\n",
    "housing[\"income_cat\"].hist()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a new attribute that cuts (pandas qcut function) Median Income into 5 different bins by defined quartiles\n",
    "housing[\"income_cat\"] = pd.qcut(housing[\"median_income\"], q=[0, .15, .3, .5, .8,  1], labels=[1,2,3,4,5])\n",
    "#NOTE that these quartile values are a bit odd (inconsistent to help demonstrate a point) - a typical cut would be [0,.25,.5,.75,1]\n",
    "\n",
    "#see that this column has a distribution based on defined quartiles \n",
    "housing[\"income_cat\"].hist()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Bin Median Income"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a new attribute that cuts (pandas cut function) Median Income into 5 different bins by defining the bin values\n",
    "housing[\"income_cat\"] = pd.cut(housing[\"median_income\"],\n",
    "                               bins=[0., 1.5, 3.0, 4.5, 6., np.inf],\n",
    "                               labels=[1, 2, 3, 4, 5])\n",
    "\n",
    "#see that this column has a normal distribution of income data\n",
    "housing[\"income_cat\"].hist()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=blue>Analyze the Data some more</blue>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot the training data set using the pandas plot wrapper\n",
    "#Note: by making alpha less than 1, the graph is more transparent\n",
    "housing.plot(kind=\"scatter\", x=\"longitude\", y=\"latitude\", alpha=.1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add population to the graph - population sets the size (s) of the dots\n",
    "#add median house value as the color of the dots using a predefined color mapping called jet\n",
    "#sharex turns off sharing of the x axis\n",
    "housing.plot(kind=\"scatter\", x=\"longitude\", y=\"latitude\", alpha=0.4,\n",
    "    s=housing[\"population\"]/100, label=\"population\", figsize=(10,7),\n",
    "    c=\"median_house_value\", cmap=plt.get_cmap(\"jet\"), colorbar=True, \n",
    "    sharex=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Population is Highly Correlated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from the graph above, can see the correlation of housing price and location (latitude/longitude)\n",
    "#let's look at it statistically by analyzing the correlation of median_house_value to all other attributes\n",
    "housing.corr(numeric_only = True)[\"population\"].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=blue>Bring Context to Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#look at ratio of rooms and population per household\n",
    "housing[\"rooms_per_household\"] = housing[\"total_rooms\"]/housing[\"households\"]\n",
    "housing[\"population_per_household\"]=housing[\"population\"]/housing[\"households\"]\n",
    "\n",
    "#also look at bedrooms in relation to number of rooms\n",
    "housing[\"bedrooms_per_room\"] = housing[\"total_bedrooms\"]/housing[\"total_rooms\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=blue>Cleanse the Data</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore Missing Values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find attributes with missing values\n",
    "housing.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#for the training set, only total_bedrooms is missing values\n",
    "housing[ housing['total_bedrooms'].isna() ].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=Red>NOTE that one option here is to drop all records/rows that have NaN values using <font color=black>housing.dropna(inplace=True)</font>. In doing so, however, there is data loss that may (or may not) lead to bias.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to preserver rows with NaN, we can use SimpleImputer to fill in missing values with the median value\n",
    "imputer = SimpleImputer(strategy=\"median\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imputers only work on numeric attributes so we must drop ocean proximity column\n",
    "#note that we are creating a new dataframe here called housing_num\n",
    "housing_num = housing.drop(columns=['ocean_proximity'])\n",
    "\n",
    "#now fit the imputer to the dataset\n",
    "imputer.fit(housing_num)\n",
    "\n",
    "#see the results\n",
    "imputer.statistics_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#apply imputation to housing_num\n",
    "X=imputer.transform(housing_num)\n",
    "\n",
    "#add this tranformation back into a dataframe\n",
    "housing_tr=pd.DataFrame(X, columns = housing_num.columns, index = housing_num.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the new training data set has no missing values\n",
    "housing_tr.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert Categorical Information into Numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#analyze the categorical attribute ocean_proximity and count how many rows (i.e. districts) belong to each category\n",
    "housing[\"ocean_proximity\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#look at the top 10 rows in the dataframe \n",
    "housing[\"ocean_proximity\"].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create categorical information using Ordinal Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create an ordinal encorder object and fit the attribte housing_cat to it\n",
    "#if you do not define categories, the ordinality will be defined for you\n",
    "#in this case, we created the order where ISLAND should be 0, NEAR OCEAN 1 ...\n",
    "proximity_ord = ['ISLAND', 'NEAR OCEAN', 'NEAR BAY', '<1H OCEAN', 'INLAND']\n",
    "ordinal_encoder = OrdinalEncoder(categories=[proximity_ord])\n",
    "housing_cat_encoded = ordinal_encoder.fit_transform(housing[['ocean_proximity']])\n",
    "#Note: use of [[ ]] creates a dataframe from the single attribute ocean_proximity\n",
    "\n",
    "#the result is an array where categorical values are given to each unique value in the attribute\n",
    "housing_cat_encoded[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#here is the list of categories\n",
    "ordinal_encoder.categories_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add this array as a new column to the dataframe\n",
    "housing['ocean_prox_ordinal'] = housing_cat_encoded\n",
    "housing.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create categorical information using One Hot Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a categoriacl encorder object and then fit & transform the data from the ocean proximity attribute\n",
    "cat_encoder=OneHotEncoder()\n",
    "housing_cat_1hot= cat_encoder.fit_transform(housing[['ocean_proximity']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#here is the list of categories that were created\n",
    "cat_encoder.categories_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#here is what the result looks like in a dataframe\n",
    "categorical_df = pd.DataFrame.sparse.from_spmatrix(housing_cat_1hot, columns=cat_encoder.categories_)\n",
    "categorical_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=blue>Create a Training and Test Set </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Traditional Train / Test Split Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#while there are several ways to generate a test vs. training data set, \n",
    "#the easiest method is to use the Scikit-learn function train_test_split\n",
    "\n",
    "#train_test_split if seeded with the same random state, will generate the same 2 sets everytime\n",
    "#this is beneficial when trying to compare models\n",
    "\n",
    "train_set, test_set = train_test_split(housing, test_size=0.2, random_state=42)\n",
    "#train_test_split returns 2 different dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Data set size: {:,}\\nTraining set size: {:,} \\nTest set size (20%): {:,}\".format(len(housing),len(train_set),len(test_set)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#look to see if the test and training sets are representative of the origial dataframe with regards to the income distribution\n",
    "pd.DataFrame( { \"Overall\": housing[\"income_cat\"].value_counts() / len(housing), \n",
    "               \"Training\": train_set[\"income_cat\"].value_counts() / len(train_set),\n",
    "               \"Test\": test_set[\"income_cat\"].value_counts() / len(test_set)})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a Stratified Sampling based on <i>Medium Income"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#by adding the stratify feature to the train_test_split, can ensure a more representative collection of data\n",
    "strat_train_set, strat_test_set = train_test_split(housing, test_size=0.2, random_state=42, stratify=housing.income_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Data set size: {:,}\\nTraining set size: {:,} \\nTest set size (20%): {:,}\".format(\n",
    "    len(housing),len(strat_train_set),len(strat_test_set)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#see that the startified test set is MORE representative of the origial dataframe than before\n",
    "#with regards to the income distribution\n",
    "pd.DataFrame( { \"Overall\": housing[\"income_cat\"].value_counts() / len(housing), \n",
    "               \"Training\": strat_train_set[\"income_cat\"].value_counts() / len(strat_train_set),\n",
    "               \"Test\": strat_test_set[\"income_cat\"].value_counts() / len(strat_test_set)})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now that we have explored the data and learned ways to transform it, move on to Part 2 to see how a model is built."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
